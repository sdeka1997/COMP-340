{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automating article retrieval in medicine\n",
    "The medical literature is enormous. Pubmed, a database of medical publications maintained by the U.S. National Library of Medicine, has indexed over 23 million medical publications. Further, the rate of medical publication has increased over time, and now there are nearly 1 million new publications in the field each year, or more than one per minute.\n",
    "\n",
    "The large size and fast-changing nature of the medical literature has increased the need for automating retrievals of  papers on a particular topic from search databases like Pubmed and then reporting results from the papers found. While such paper searches are often performed manually, with multiple people reviewing each search result, this is tedious and time consuming. In this problem, we will see how text analytics can be used to automate the process of information retrieval.\n",
    "\n",
    "The dataset consists of the titles (variable title) and abstracts (variable abstract) of papers retrieved in a Pubmed search. Each search result is labeled with whether the paper is a clinical trial testing a drug therapy for cancer (variable trial). These labels were obtained by two people reviewing each search result and accessing the actual paper if necessary, as part of a literature review of clinical trials testing drug therapies for advanced and metastatic breast cancer. This data can be downloaded from the datasets folder on canvas under week6. The dataset is called clinical_trial.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data \n",
    "- data has titles and abstracts with labels on whether papers are on a clinical trial or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>trial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Treatment of Hodgkin's disease and other cance...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cell mediated immune status in malignancy--pre...</td>\n",
       "      <td>Twenty-eight cases of malignancies of differen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neoadjuvant vinorelbine-capecitabine versus do...</td>\n",
       "      <td>BACKGROUND: Among breast cancer patients, nonr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Randomized phase 3 trial of fluorouracil, epir...</td>\n",
       "      <td>BACKGROUND: Taxanes are among the most active ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is first-line single-agent mitoxantrone in the...</td>\n",
       "      <td>BACKGROUND: To determine whether patients with...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Treatment of Hodgkin's disease and other cance...   \n",
       "1  Cell mediated immune status in malignancy--pre...   \n",
       "2  Neoadjuvant vinorelbine-capecitabine versus do...   \n",
       "3  Randomized phase 3 trial of fluorouracil, epir...   \n",
       "4  Is first-line single-agent mitoxantrone in the...   \n",
       "\n",
       "                                            abstract  trial  \n",
       "0                                                         1  \n",
       "1  Twenty-eight cases of malignancies of differen...      0  \n",
       "2  BACKGROUND: Among breast cancer patients, nonr...      1  \n",
       "3  BACKGROUND: Taxanes are among the most active ...      1  \n",
       "4  BACKGROUND: To determine whether patients with...      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('clinical_trial.csv')\n",
    "data = data.fillna('')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory data analysis\n",
    "- How many characters are there in the longest abstract? (Longest here is defined as the abstract with the largest number of characters.)\n",
    "- How many search results have no abstract? A paper has no abstract if the number of characters in the abstract field is zero.\n",
    "- Find the paper with the minimum number of characters in the title. What is the text of the title of this article? Include capitalization and punctuation in your response, but don't include the quotes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3708\n",
      "112\n",
      "A decade of letrozole: FACE.\n"
     ]
    }
   ],
   "source": [
    "# your code for the questions above\n",
    "# 2-3 lines of code per question\n",
    "titles = list(data.title)\n",
    "ab_len = [len(item) for item in data.abstract]\n",
    "\n",
    "#1\n",
    "print(max(ab_len))\n",
    "\n",
    "#2\n",
    "print(ab_len.count(0))\n",
    "\n",
    "#3\n",
    "print(min(titles, key=len))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing title data for textual analysis\n",
    "\n",
    "Use the CountVectorizer() feature extractor in sklearn.feature_extraction.text to build a term-document matrix for paper titles.\n",
    "\n",
    "- make an instance vec of CountVectorizer() with stop_words='english' and min_df = 0.05\n",
    "- use the fit_transform method of vec to transform the column data.title into a term document matrix tdm (of type scipy.sparse.csr.csr_matrix)\n",
    "- make a new pandas dataframe called df_title with tdm (converted to a regular numpy array using .toarray()) with columns equal to the feature names of vec (vec.get_feature_names())\n",
    "- What is the most frequent word across all the titles? Hint: you can use .sum() to compute the frequency of a word across all the titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "breast              1706\n",
       "cancer              1644\n",
       "patients             637\n",
       "trial                628\n",
       "chemotherapy         527\n",
       "study                495\n",
       "adjuvant             429\n",
       "phase                418\n",
       "randomized           412\n",
       "metastatic           380\n",
       "advanced             325\n",
       "treatment            319\n",
       "tamoxifen            309\n",
       "therapy              286\n",
       "ii                   279\n",
       "women                227\n",
       "versus               222\n",
       "positive             209\n",
       "group                206\n",
       "results              189\n",
       "dose                 185\n",
       "cyclophosphamide     184\n",
       "postmenopausal       176\n",
       "node                 169\n",
       "plus                 152\n",
       "high                 147\n",
       "docetaxel            139\n",
       "early                136\n",
       "doxorubicin          135\n",
       "combination          132\n",
       "clinical             131\n",
       "fluorouracil         130\n",
       "receptor             126\n",
       "iii                  125\n",
       "line                 107\n",
       "controlled           105\n",
       "response             104\n",
       "negative             102\n",
       "randomised            97\n",
       "risk                  95\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "# about 4-5 lines of code\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(stop_words='english', min_df=.05)\n",
    "\n",
    "X = cv.fit_transform(data['title'])\n",
    "df_title = pd.DataFrame(X.toarray(), columns=cv.get_feature_names())\n",
    "df_title.sum().sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing abstract data for textual analysis\n",
    "\n",
    "Use the CountVectorizer() feature extractor in sklearn.feature_extraction.text to build a term-document matrix for paper abstracts.\n",
    "\n",
    "- make an instance vec_abs of CountVectorizer() with stop_words='english' and min_df = 0.05\n",
    "- use the fit_transform method of vec_abs to transform the column data.abstract into a term document matrix tdm_abs (of type scipy.sparse.csr.csr_matrix)\n",
    "- make a new pandas dataframe called df_abstract with tdm_abs (converted to a regular numpy array using .toarray()) with columns equal to the feature names of vec_abs (vec_abs.get_feature_names())\n",
    "- What is the most frequent word across all the abstracts? Hint: you can use .sum() to compute the frequency of a word across all the abstracts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patients           8078\n",
       "breast             3942\n",
       "cancer             3640\n",
       "treatment          2880\n",
       "mg                 2570\n",
       "chemotherapy       2456\n",
       "group              1922\n",
       "survival           1902\n",
       "response           1779\n",
       "tamoxifen          1712\n",
       "study              1571\n",
       "therapy            1534\n",
       "months             1521\n",
       "women              1490\n",
       "results            1375\n",
       "dose               1323\n",
       "disease            1317\n",
       "adjuvant           1194\n",
       "positive           1185\n",
       "median             1179\n",
       "years              1168\n",
       "trial              1147\n",
       "randomized         1054\n",
       "significant        1050\n",
       "treated             994\n",
       "95                  978\n",
       "overall             956\n",
       "compared            944\n",
       "significantly       903\n",
       "received            867\n",
       "                   ... \n",
       "43                  120\n",
       "studied             117\n",
       "shown               117\n",
       "endpoint            116\n",
       "improve             115\n",
       "completed           115\n",
       "77                  114\n",
       "alopecia            114\n",
       "times               113\n",
       "performance         113\n",
       "41                  113\n",
       "56                  112\n",
       "comparing           111\n",
       "defined             111\n",
       "47                  110\n",
       "analyzed            110\n",
       "57                  109\n",
       "characteristics     109\n",
       "entered             109\n",
       "potential           107\n",
       "61                  107\n",
       "statistical         106\n",
       "determined          104\n",
       "considered          104\n",
       "available           103\n",
       "54                  103\n",
       "examined            102\n",
       "66                  100\n",
       "62                  100\n",
       "69                   98\n",
       "Length: 396, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "# about 4-5 lines of code\n",
    "\n",
    "abstracts = CountVectorizer(stop_words='english', min_df=.05)\n",
    "\n",
    "X = abstracts.fit_transform(data['abstract'])\n",
    "df_abstract = pd.DataFrame(X.toarray(), columns=abstracts.get_feature_names())\n",
    "df_abstract.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert column names in df_title and df_abstract\n",
    "- append the string 't_' to the names of columns in df_title\n",
    "- append the string 'a_' to the names of columns in df_abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here (about 2 lines)\n",
    "df_title.columns = ['t_' + x for x in df_title.columns]\n",
    "df_abstract.columns = ['a_' + x for x in df_abstract.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a new dataframe by combining df_title and df_abstract\n",
    "- concatenate the two dataframes along axis = 1\n",
    "- Then construct a 2d numpy array X with the values in this new dataframe (these are the features of the term-document model)\n",
    "- make the numpy vector y be the values in data['trial'] (the labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "matrix1 = pd.concat([df_title, df_abstract], axis=1)\n",
    "\n",
    "X = matrix1.values\n",
    "y = data['trial'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a decision tree with X and y\n",
    "- First split X,y into a train and test set (test size = 30%)\n",
    "- fit sklearn's DecisionTreeClassifier with max_depth of 3 on the training X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remember to import sklearn's model_selection, tree modules\n",
    "# about 3-4 lines of code (not counting the imports)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "clf = DecisionTreeClassifier(max_depth=3)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the constructed decision tree using graphviz\n",
    "- see the dtrees.ipynb notebook for an example\n",
    "- which feature is at the root of the decision tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'Source'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-85905d09cde7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdot_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_graphviz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmatrix1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrounded\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecial_characters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'Source'"
     ]
    }
   ],
   "source": [
    "# your viz code here\n",
    "from graphviz\n",
    "\n",
    "dot_data = sklearn.tree.export_graphviz(clf, out_file=None, feature_names=matrix1.columns, filled=True, rounded=True, special_characters=True)\n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate performance of learned decision tree on the training X and y\n",
    "- calculate confusion matrix with training set\n",
    "- calculate specificity and sensitivity on training set\n",
    "- calculate training set AUC\n",
    "- use .predict() and .predict_proba() on the classifier to predict labels and to predict probabilities of the two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[637  93]\n",
      " [203 369]]\n",
      "Training set accuracy: 0.7726574500768049\n",
      "Specificity: 0.8726027397260274\n",
      "Sensitivity: 0.6451048951048951\n",
      "Training AUC: 0.8292640578599484\n"
     ]
    }
   ],
   "source": [
    "# 8-10 lines of code here using sklearn metrics functions\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y_pred_dis = clf.predict(X_train)\n",
    "y_pred = clf.predict_proba(X_train)\n",
    "\n",
    "print(confusion_matrix(y_train, y_pred_dis))\n",
    "print ('Training set accuracy: ' + str(accuracy_score(y_train, y_pred_dis)))\n",
    "\n",
    "tn1, fp1, fn1, tp1 = confusion_matrix(y_train, y_pred_dis).ravel()\n",
    "spec1 = tn1 / (tn1 + fp1)\n",
    "sens1 = tp1 / (tp1 + fn1)\n",
    "\n",
    "print ('Specificity: ' + str(spec1))\n",
    "print ('Sensitivity: ' + str(sens1))\n",
    "print ('Training AUC: ' + str(roc_auc_score(y_train, y_pred[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate performance of learned decision tree on the set aside test X and y\n",
    "- calculate confusion matrix with training set\n",
    "- calculate specificity and sensitivity on training set\n",
    "- calculate training set AUC\n",
    "- use .predict() and .predict_proba() on the classifier to predict labels and to predict probabilities of the two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[273  40]\n",
      " [ 95 150]]\n",
      "Training set acc0.7580645161290323\n",
      "Specificity: 0.8722044728434505\n",
      "Sensitivity: 0.6122448979591837\n",
      "Test AUC: 0.8275542804981416\n"
     ]
    }
   ],
   "source": [
    "# 8-10 lines of code here using sklearn metrics functions\n",
    "y_pred_dis = clf.predict(X_test)\n",
    "y_pred = clf.predict_proba(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred_dis))\n",
    "print ('Training set acc' + str(accuracy_score(y_test, y_pred_dis)))\n",
    "\n",
    "tn2, fp2, fn2, tp2 = confusion_matrix(y_test, y_pred_dis).ravel()\n",
    "spec2 = tn2 / (tn2 + fp2)\n",
    "sens2 = tp2 / (tp2 + fn2)\n",
    "\n",
    "print ('Specificity: ' + str(spec2))\n",
    "print ('Sensitivity: ' + str(sens2))\n",
    "print ('Test AUC: ' + str(roc_auc_score(y_test, y_pred[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vary max_depth in your classifier definition \n",
    "- Describe the impact on classifier performance in the training and the test set.\n",
    "- test out depths from 1 to 10 and compute training set AUC and test set AUC for each tree with a 70/30 train/test split\n",
    "- plot depth on x-axis and AUC on y-axis for both training and test set\n",
    "- to what depth should you grow a tree for this problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here varying classifier depth\n",
    "# about 14-15 lines of code\n",
    "import numpy as np\n",
    "depthData = pd.DataFrame(columns=['trainAUC', 'testAUC'])\n",
    "\n",
    "depths = np.arange(1,11)\n",
    "trainAUCs = []\n",
    "testAUCs = []\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "for depth in depths:\n",
    "    clf = DecisionTreeClassifier(max_depth=depth)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_predTest = clf.predict_proba(X_test)\n",
    "    y_predTrain = clf.predict_proba(X_train)\n",
    "    depthData.at[depth,'trainAUC'] = roc_auc_score(y_train, y_predTrain[:,1])\n",
    "    depthData.at[depth,'testAUC'] = roc_auc_score(y_test, y_predTest[:,1])\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#     trainAUCs.append(roc_auc_score(y_train, ypredTrain[:,1]))\n",
    "#     testAUCs.append(roc_auc_score(y_test, ypredTest[:,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1750b6d8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "depthData.plot(use_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the impact of false positives and false negatives in the prediction process\n",
    "\n",
    " \n",
    "A researcher searching for relevant papers on clinical trials in the medical literature would use a model like the one we built above, in the following workflow:\n",
    "\n",
    "1) For all of the papers retrieved in a keyword-based PubMed Search, predict which papers are clinical trials using our model. This yields some initial Set A of papers predicted to be trials, and some Set B of papers predicted not to be trials. \n",
    "\n",
    "2) Then, the researcher manually reviews all papers in Set A, verifying that each paper meets the inclusion criteria (for the purposes of this analysis, we assume this manual review is 100% accurate at identifying whether a paper in Set A is a relevant paper on clinical trials). This yields a more limited set of papers to be analyzed further, which would ideally be all papers in the medical literature meeting the relevance criteria (be about a clinical trial in breast cancer).\n",
    "\n",
    "3) Perform the required analysis, using data extracted from the limited set of papers identified in step 2.\n",
    "\n",
    "Now pick the best choice for the three questions below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "What is the cost associated with the model in Step 1 making a false negative prediction?\n",
    "\n",
    "- A: A paper will be mistakenly added to Set A, yielding additional work in Step 2 of the process but not affecting the quality of the results of Step 3.\n",
    "- B: A paper will be mistakenly added to Set A, definitely affecting the quality of the results of Step 3.\n",
    "- #### C: A paper that should have been included in Set A will be missed, affecting the quality of the results of Step 3. \n",
    "- D: There is no cost associated with a false negative prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "What is the cost associated with the model in Step 1 making a false positive prediction?\n",
    "\n",
    "- #### A: A paper will be mistakenly added to Set A, yielding additional work in Step 2 of the process but not affecting the quality of the results of Step 3. \n",
    "- B: A paper will be mistakenly added to Set A, definitely affecting the quality of the results of Step 3.\n",
    "- C: A paper that should have been included in Set A will be missed, affecting the quality of the results of Step 3.\n",
    "- D: There is no cost associated with a false positive prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "Given the costs associated with false positives and false negatives, which of the following is most accurate?\n",
    "\n",
    "\n",
    "- A: A false positive is more costly than a false negative; the decision maker should use a probability threshold greater than 0.5 for the machine learning model.\n",
    "- B: A false positive is more costly than a false negative; the decision maker should use a probability threshold less than 0.5 for the machine learning model.\n",
    "- C: A false negative is more costly than a false positive; the decision maker should use a probability threshold greater than 0.5 for the machine learning model.\n",
    "- #### D: A false negative is more costly than a false positive; the decision maker should use a probability threshold less than 0.5 for the machine learning model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
